{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCMXozdVmCD4",
        "outputId": "4ab7ba16-695e-48c9-bb21-62ba1f82691d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "# !pip uninstall numpy gensim -y\n",
        "# !pip install numpy==1.23.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XeaWVRyLkVWt",
        "outputId": "2edcfe17-a817-4fd1-a835-4f8b4ec8d50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CcOQIvkGlV7l",
        "outputId": "b887bbc5-76fc-4f61-f0f9-44450aff5429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.23.5)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, gensim\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 scipy-1.13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NP5PG8LFj9OO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# import gensim.downloader as api\n",
        "import importlib\n",
        "import tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  text = f.read()\n",
        "print(len(text))\n",
        "text[:99]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "j2Il-PMjlRVB",
        "outputId": "963bff20-2bce-495f-d3e4-f6c4953b995e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "cKYb9nZIcJU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens = len(tokenizer.encode(text))\n",
        "print(total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO6Je6RMcksu",
        "outputId": "c1304ef1-f6c7-4fa2-c9f9-72ebfaa3c0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class gptdataset(Dataset):\n",
        "    def __init__(self,txt,tokenizer,max_len,stride):\n",
        "      self.input_ids = []\n",
        "      self.target_ids = []\n",
        "\n",
        "      token_ids = tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "      for i in range(0,len(token_ids)-max_len, stride):\n",
        "        input_chunk = token_ids[i:i+max_len]\n",
        "        target_chunk = token_ids[i+1:i+max_len+1]\n",
        "        self.input_ids.append(torch.tensor(input_chunk))\n",
        "        self.target_ids.append(torch.tensor(target_chunk))\n",
        "    def __len__(self):\n",
        "      return len(self.input_ids)\n",
        "    def __getitem__(self,idx):\n",
        "      return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "EvGaQzjKlqMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(txt,stride=128,shuffle=True,drop_last=True,num_workers=4,max_len=256,batch_size=4):\n",
        "  dataset = gptdataset(txt,tokenizer,max_len,stride)\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle =shuffle,\n",
        "      drop_last = drop_last,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "pgLaI1d0l61W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"con_len\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "iRwZhqn_mqDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = .90\n",
        "split_idx = int(train_ratio*len(text))\n",
        "train_data = text[:split_idx]\n",
        "val_data = text[split_idx:]\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_loader = create_dataloader(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_len=gpt_124M[\"con_len\"],\n",
        "    stride=gpt_124M[\"con_len\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_len=gpt_124M[\"con_len\"],\n",
        "    stride=gpt_124M[\"con_len\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "qjUCJs65c_Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.att = MultiHeadAttention(cfg[\"emb_dim\"],cfg[\"emb_dim\"],cfg[\"con_len\"],cfg[\"drop_rate\"],cfg[\"n_heads\"],cfg[\"bias\"])\n",
        "    self.ffn = feedforward(cfg)\n",
        "    self.ln1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.ln2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut = x\n",
        "    x=self.ln1(x)\n",
        "    x=self.att(x)\n",
        "    x=self.drop_shortcut(x)\n",
        "    x=x+shortcut\n",
        "    shortcut=x\n",
        "    x=self.ln2(x)\n",
        "    x=self.ffn(x)\n",
        "    x=self.drop_shortcut(x)\n",
        "    x=x+shortcut\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "2OJAowJY_ATg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "zqo1507cmcbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GeLU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return 0.5*x*(1+torch.tanh(torch.sqrt(torch.tensor(2.0/torch.pi))*(x+0.044715*torch.pow(x,3))))\n"
      ],
      "metadata": {
        "id": "1uePM4Vn-_M0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class feedforward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
        "        GeLU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"]),\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layer(x)"
      ],
      "metadata": {
        "id": "oGLWvhYx_AWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT_2(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"],cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"con_len\"],cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(cfg[\"emb_dim\"],cfg[\"vocab_size\"],bias = False)\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len,device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits\n",
        "torch.manual_seed(123)\n",
        "model = GPT_2(gpt_124M)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zVKwkxiJ_AN_",
        "outputId": "7f179158-93fe-4425-a4d3-c28bf97725f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT_2(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "4FXOF_rXfZX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "with torch.no_grad():\n",
        "  train_loss = calc_loss_loader(train_loader,model,device)\n",
        "  val_loss = calc_loss_loader(val_loader,model,device)\n",
        "\n",
        "  print(f\"Train loss: {train_loss:.4f}\")\n",
        "  print(f\"Val loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgcAzfqvguzx",
        "outputId": "ee8f8f9c-589b-4fe3-c843-63ae7c8484fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 10.9876\n",
            "Val loss: 10.9811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader,val_loader, device,eval_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader,model,device,eval_iter)\n",
        "    val_loss = calc_loss_loader(val_loader,model,device,eval_iter)\n",
        "  model.train()\n",
        "  return train_loss,val_loss\n"
      ],
      "metadata": {
        "id": "AgckS46HmzKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "  idx = idx.to(next(model.parameters()).device)\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:]\n",
        "    with torch.no_grad():\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :]\n",
        "\n",
        "    if top_k is not None:\n",
        "      top_logits, _ = torch.topk(logits, top_k)\n",
        "      min_val = top_logits[:, -1]\n",
        "      logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "    if temperature > 0.0:\n",
        "      logits = logits / temperature\n",
        "      probs = torch.softmax(logits, dim=-1)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "    else:\n",
        "      idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "    if idx_next == eos_id:\n",
        "      break\n",
        "\n",
        "    idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "  return idx"
      ],
      "metadata": {
        "id": "jTew_2jVoPBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token(text,tokenizer):\n",
        "  encoded = tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "  encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded_tensor\n",
        "\n",
        "def token_to_text(token_ids,tokenizer):\n",
        "  flat = token_ids.squeeze(0)\n",
        "  return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_cotext = \"every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token(start_cotext,tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=gpt_124M[\"con_len\"],\n",
        ")\n",
        "token_to_text(token_ids,tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "grp2hAQPoKXe",
        "outputId": "5cb0ea25-7fc9-45fe-b3e4-582033ed2234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'every effort moves you rentingetic minion mobilized Macicone heterogeneity\\x00achaRAM'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "Z-aDki_Nnrec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "XGa0aM3kj6pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPT_2(gpt_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay =0.9)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses ,val_losses,token_seen = train_model(model,train_loader,val_loader,optimizer,device,num_epochs,eval_freq=5,eval_iter=5,start_context=\"Every effort moves you\",tokenizer=tokenizer)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_min = (end_time - start_time) / 60\n",
        "print(f\"Training time: {execution_time_min:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAFpjg3nnRRt",
        "outputId": "b8d51444-d58d-4de9-d706-ada880f9c7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.931\n",
            "Ep 1 (Step 000005): Train loss 8.072, Val loss 8.341\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.631, Val loss 7.059\n",
            "Ep 2 (Step 000015): Train loss 6.050, Val loss 6.606\n",
            "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.544, Val loss 6.499\n",
            "Ep 3 (Step 000025): Train loss 5.425, Val loss 6.393\n",
            "Every effort moves you, and to the to the of the to the, and I had. G.                                 \n",
            "Ep 4 (Step 000030): Train loss 4.947, Val loss 6.286\n",
            "Ep 4 (Step 000035): Train loss 4.694, Val loss 6.285\n",
            "Every effort moves you, and I had been the of the picture to the picture.               \"I\"I had the picture.    \"I had been the of the picture. \n",
            "Ep 5 (Step 000040): Train loss 4.125, Val loss 6.162\n",
            "Every effort moves you know the                                                \n",
            "Ep 6 (Step 000045): Train loss 3.727, Val loss 6.164\n",
            "Ep 6 (Step 000050): Train loss 3.179, Val loss 6.159\n",
            "Every effort moves you know the was his a little the.                    \"I was his pictures--I looked.             \n",
            "Ep 7 (Step 000055): Train loss 3.111, Val loss 6.179\n",
            "Ep 7 (Step 000060): Train loss 2.418, Val loss 6.115\n",
            "Every effort moves you know the picture to see the picture.                    \"I he was his pictures-c his pictures--the his pictures--and--I he's the his\n",
            "Ep 8 (Step 000065): Train loss 1.980, Val loss 6.131\n",
            "Ep 8 (Step 000070): Train loss 1.687, Val loss 6.200\n",
            "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
            "Ep 9 (Step 000075): Train loss 1.345, Val loss 6.216\n",
            "Ep 9 (Step 000080): Train loss 1.061, Val loss 6.229\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
            "Ep 10 (Step 000085): Train loss 0.806, Val loss 6.304\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Training time: 0.60 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, token_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "FHvWhpNNqHdZ",
        "outputId": "4405605d-0590-4f27-999d-d21cab9efec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),\"gpt_124M.pt\")"
      ],
      "metadata": {
        "id": "QvmHFhHmtmeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT_2(gpt_124M)\n",
        "state_dict = torch.load(\"gpt_124M.pt\")\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4_WAAOwQKiaT",
        "outputId": "47418cd1-91fa-4e98-c19d-00136e1a3f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT_2(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ffn): feedforward(\n",
              "        (layer): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GeLU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (ln1): LayerNorm()\n",
              "      (ln2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\"model_state_dict\": model.state_dict(),\"optimizer_state_dict\": optimizer.state_dict()},\"model_and_optimizer.pth\")"
      ],
      "metadata": {
        "id": "sPGeLbIwKiWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints = torch.load(\"model_and_optimizer.pth\")\n",
        "model = GPT_2(gpt_124M)\n",
        "model.load_state_dict(checkpoints[\"model_state_dict\"])\n",
        "optimizer = torch.optim.AdamW(model.parameters(),lr=0.0004,weight_decay =0.9)\n",
        "optimizer.load_state_dict(checkpoints[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "Fqs1OOwOKiUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQ1--9gvKiRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nSEJI8iSKiOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNtSyhsKKiL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZKFefARtKiJJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}